# "Real-Time Blood Pressure Monitoring with FHIR, Kafka, Elasticsearch & Kibana"

Ce projet impl√©mente un pipeline de donn√©es Big Data con√ßu pour la surveillance en temps r√©el de la pression art√©rielle, tout en constituant une simulation acad√©mique d‚Äôun syst√®me de monitoring. Les donn√©es de pression art√©rielle sont enti√®rement g√©n√©r√©es de mani√®re synth√©tique √† l‚Äôaide de scripts Python et ne proviennent d‚Äôaucun dispositif m√©dical r√©el. L‚Äôobjectif est de d√©montrer la capacit√© du pipeline, bas√© sur le standard FHIR, √† traiter, filtrer et visualiser en continu des flux de donn√©es cliniques simul√©es, afin d‚Äôidentifier et d‚Äôanalyser automatiquement les anomalies d√©tect√©es.


## Architecture du syst√®me
Le pipeline repose sur une architecture "Event-Driven" optimis√©e pour la haute disponibilit√© et la scalabilit√© :

1. **Patient Data Producer (Python)** : Simule des capteurs m√©dicaux connect√©s g√©n√©rant des flux de donn√©es au format FHIR (ID patient, timestamp, pressions systolique et diastolique).
2. **Message Broker (Apache Kafka)** : Assure le transport fiable et ordonn√© des flux de donn√©es.
3. **Smart Consumer (Python)** : Analyse le flux en temps r√©el et applique un filtrage s√©lectif : seules les anomalies (Systolique > 140 mmHg ou Diastolique > 90 mmHg) sont extraites pour indexation.
4. **Storage & Indexing (Elasticsearch)** : Utilisation d'un index d√©di√© `bp_anomalies` pour stocker les dossiers critiques de mani√®re optimis√©e.
5. **Clinical Dashboard (Kibana)** : Interface de visualisation pour l‚Äôanalyse et la supervision des flux de donn√©es simul√©es.

## Structure du r√©pertoire

L'organisation du projet suit une architecture modulaire pour s√©parer la g√©n√©ration, le traitement et la visualisation des donn√©es :

```text
 cardiac-monitoring-kafka
 ‚î£ üìÇ producer
 ‚îÉ ‚îó producer.py      # Script de simulation des capteurs FHIR (Kafka Producer)
 ‚î£ üìÇ consumer
 ‚îÉ ‚îó consumer.py      # Script de filtrage et d'indexation vers Elasticsearch
 ‚î£ üìÇ kibana
 ‚îÉ ‚îó dashboard_export.ndjson  # Export des visualisations et du dashboard clinique
 ‚î£ üìÇ docs
 ‚îÉ ‚îó kibana-dashboard.pdf # Dashboard Kibana : Triage et D√©tection d'Anomalies en Temps R√©el
 ‚îÉ Message_FHIR_Project.py
 ‚î£ docker-compose.yml         # Orchestration des services Kafka, Zookeeper et ELK
 ‚î£ requirements.txt           # Liste des d√©pendances Python (kafka-python, elasticsearch)
 ‚î£ .gitignore                 # Exclusion des fichiers temporaires et des caches Python
 ‚îó README.md                  # Documentation principale du projet
```

## Dashboard de supervision m√©dicale
L'interface Kibana offre une vue d√©cisionnelle compl√®te :
* **Indices de gravit√© (Gauges)** : Suivi en temps r√©el du pic de tension (Max) et de la moyenne du service pour une √©valuation rapide du danger.
* **Analyse de tendance (Line Chart)** : Monitoring des cycles de pression art√©rielle et d√©tection des pics temporels.
* **Typologie des risques (Pie Chart)** : R√©partition qualitative des types d'hypertension d√©tect√©s.
* **Tableau de priorisation des anomalies d√©tect√©es(Table)** : Liste prioris√©e des 5 patients les plus critiques pour une intervention imm√©diate.

## Installation & utilisation

### Pr√©-requis
* Docker & Docker-Compose
* Python 3.x
* Biblioth√®ques : `kafka-python`, `elasticsearch`

### Lancement de l'infrastructure
```bash
docker-compose up -d
# Lancer le consommateur (d√©tection d'anomalies)
python consumer/consumer.py

# Lancer le producteur (simulation des donn√©es patients)
python producer/producer.py
```

### Importer le Dashboard
Pour visualiser le dashboard clinique :
1. Allez dans **Stack Management** > **Saved Objects** sur votre instance Kibana.
2. Cliquez sur **Import** et s√©lectionnez le fichier `kibana/dashboard_monitoring.ndjson`.
3. Le dashboard complet, incluant les jauges de gravit√© et le registre de triage, sera automatiquement recr√©√©.

Projet acad√©mique - 2026
